{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ac434bf-e442-47a7-8d5c-af1f216fa28e",
   "metadata": {},
   "source": [
    "# **深度学习系列：感知机（perceptron）**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a7d581-9b2a-433d-83e5-2858b5ec8531",
   "metadata": {},
   "source": [
    "在机器学习中，感知机（perceptron）是一种简单而经典的分类模型，只有 **输入层** 和 **输出层**，是 **二分类的线性分类器**。它可以解决**与（AND）**、**或（OR）** 等简单的线性可分问题，但无法解决复杂的 **异或（XOR）** 等非线性可分问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70200537-dac6-4638-b236-9cf0ddaaf765",
   "metadata": {},
   "source": [
    "## **1. 单层感知机**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860c968c-9c8d-4651-bcee-6a16f2345be1",
   "metadata": {},
   "source": [
    "### 1.1 感知机（perceptron）是什么？\n",
    "- 感知机是由美国学者 `Frank Rosenblatt` 在 1957 年提出的，它是一种 **模拟人脑神经元工作原理的模型**。感知机接收多个输入信号，通过 **加权求和并加上偏置值**，然后通过一个 **激活函数** 将结果转化为输出信号。\n",
    "- 感知器是一种简单的 **二元分类器**，它试图将数据分为两类。简单来说，感知器可以被视为一个线性模型，它使用线性函数（通常是加权和）来预测输入数据的类别。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54c2230-b982-4ce1-bd73-c9884923cafc",
   "metadata": {},
   "source": [
    "### 1.2 感知机的基本结构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342e9b04-5584-481e-bf05-247bb56e16c6",
   "metadata": {},
   "source": [
    "- 输入层：由输入向量组成，每个输入都有一个权重。接收外部信息，不进行信息处理，只是将信息传递给输出层。\n",
    "- 输出层：接收输入层的信号，通过加权求和并加上偏置值，然后通过一个激活函数（如 **阶跃函数**）将结果转化为输出信号。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0c3582-945b-466f-bd3d-2f2a8d7b462a",
   "metadata": {},
   "source": [
    "为什么要学习这么古老的算法？感知机是神经网络的起源算法，它的工作原理和概念构成了深度学习算法的基础。通过了解感知机，可以掌握神经网络的基本组成单元、工作原理和训练方法，为后续学习更复杂的模型打下基础。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbf8b64-e669-4367-aa50-05481f15ce32",
   "metadata": {},
   "source": [
    "### 1.3 感知机的工作原理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01df33c7-0739-4e77-8c52-3f8984a5716f",
   "metadata": {},
   "source": [
    "单层感知机通过加权求和输入信号并加上偏置值，然后经过阶跃激活函数处理，输出二分类结果。\n",
    "- 加权求和：输入信号被送往输出层时，会被分别乘以各自的权重，然后求和。\n",
    "- 偏置值：用于调整输出层的激活阈值。\n",
    "- 激活函数：在单层感知机中，常用的 **激活函数是阶跃函数**，它将大于某个阈值的结果输出为 1，小于阈值的结果输出为 0。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cad1362-73a5-495f-aceb-27ce6b47fc45",
   "metadata": {},
   "source": [
    "### 1.4 感知机的几何解释（训练目标）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50515e0-8154-4f3b-98ed-f65123ae838f",
   "metadata": {},
   "source": [
    "- 在二维空间中，感知机的目标是找到 **一条直线**，这条直线将平面划分为两部分。\n",
    "- 在多维空间中，感知机的目标是找到 **一个超平面**，这个超平面将空间划分为两部分。\n",
    "- 以上的 **一条直线** 或 **一个超平面** 称为 **决策边界**（decision boundary）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253218bc-a676-40ab-bcb7-aa3dc059ffbb",
   "metadata": {},
   "source": [
    "<center><img src=\"images/01-deeplearning_perceptron/perceptron-merge.png\" style=\"width:90%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd309d41-c380-4d11-962d-6ad0aec71c19",
   "metadata": {},
   "source": [
    "<center>图 1.5：决策边界（直线、超平面）</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e5a169-8873-496b-a725-97d74a816bd8",
   "metadata": {},
   "source": [
    "### 1.5 感知机的数学表达式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea12681-5f8a-4715-ae29-49644e5a9481",
   "metadata": {},
   "source": [
    "假设我们有一个输入向量 $\\mathbf{x}=[x_1, x_2, \\ldots, x_n]$，并将 $\\mathbf{x}$ 视为一个样本数据，其中的 $x_1, x_2, \\ldots, x_n$ 等都是该样本的特征（$n$ 个特征），权重向量 $\\mathbf{w}=[w_1, w_2, \\ldots, w_n]$，以及一个偏置项 $b$。那么感知机的输出 $f(x)$ 可以用以下公式（**阶跃函数**）计算："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d342ddf-b47e-45c6-8662-fe620abaf51f",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "  f(x) = \\begin{cases} \n",
    "  1 & \\text{if } \\sum\\limits_{i=1}\\limits^{n} w_i x_i + b \\geq 0 \\\\ \n",
    "  -1 & \\text{if } \\sum\\limits_{i=1}\\limits^{n} w_i x_i +b < 0\n",
    "  \\end{cases} \\quad 或 \\quad f(x) = \\text{sign}(\\mathbf{w} \\cdot \\mathbf{x} + b)\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70a51ed-2d3f-43b9-989d-f9594007f5b7",
   "metadata": {},
   "source": [
    "- 其中 $\\sum\\limits_{i=1}\\limits^{n}w_i x_i$ 表示输入向量与权重向量的点积（内积）。\n",
    "- $\\text{sign}$ 是符号函数，若 $\\mathbf{w} \\cdot \\mathbf{x} + b \\geq 0$，则输出为 $1$，表示 **正类**（分类正确）；相反 $\\mathbf{w} \\cdot \\mathbf{x} + b < 0$， 则输出为 $-1$，表示 **负类**（误分类）。\n",
    "- $\\hat{y}$ 或 $\\hat{f(x)}$ 是预测值，即根据样本数据实际计算所得的值。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189588c1-b49f-44ff-b60b-2794b8294db8",
   "metadata": {},
   "source": [
    "<center><img src=\"images/01-deeplearning_perceptron/perceptron-detail-1.png\" style=\"width:90%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1b3b4b-364d-4606-acdb-f6a1de95c78b",
   "metadata": {},
   "source": [
    "<center>图 1.4：前向传播网络</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cac7459-1f10-4574-8d9a-c8fd15c98669",
   "metadata": {},
   "source": [
    "### 1.6 感知机的损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6e611a-8f11-42d4-b7ae-3590306eb045",
   "metadata": {},
   "source": [
    "感知机中误分类点集合 $M$ 的说明：\n",
    "\n",
    "在感知机的训练过程中，$M$ 表示误分类点的集合。具体来说，误分类点是指那些不满足分类条件的样本点，即对于真实的标签 $y_i$ 和感知机的预测结果 $\\text{sign}(w \\cdot x_i + b)$，当 $y_i (w \\cdot x_i + b) \\leq 0$ 时，该样本点 $(x_i, y_i)$ 被认为是误分类点，属于集合 $M$。\n",
    "\n",
    "在感知机的训练过程中，误分类点集合 $M$ 是动态变化的。随着权重 $w$ 和偏置 $b$ 的不断更新，一些原本误分类的点可能会被正确分类，从而从集合 $M$ 中移除；同时，也可能会有新的误分类点加入集合 $M$。训练的目标是通过不断调整 $w$ 和 $b$，使得集合 $M$ 最终为空，即所有样本点都被正确分类。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3be4821-c186-48ff-9fa8-1c09fb047f83",
   "metadata": {},
   "source": [
    "感知机的损失函数基于误分类点的定义。以二维空间中的点为例，对于一个误分类点 $(x_i,y_i)$，\n",
    "其满足：$y_i(w \\cdot x_i + b) \\leq 0$\n",
    "\n",
    "感知机的损失函数为所有误分类点的损失之和：\n",
    "$Loss(w,b) = -\\sum\\limits_{i \\in M} y_i(w \\cdot x_i + b)$，其中 $M$ 是所有误分类点的集合。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e35505-568c-4c56-bdac-0149c54da8fa",
   "metadata": {},
   "source": [
    "### 1.7 感知机的训练过程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e4f261-297b-417d-bcaf-382009e7cb04",
   "metadata": {},
   "source": [
    "感知机的训练过程是梯度下降法和误分类驱动的更新迭代机制。通过调整权重和偏置值，感知机可以在有限的迭代次数中收敛到一个能够将训练数据集正确分类的 **直线** 或 **超平面**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b6fb14-f04a-4f91-9910-2edb3e3863ed",
   "metadata": {},
   "source": [
    "- 定义损失函数：通常使用 **误分类点到分离超平面的距离** 作为损失函数。\n",
    "- 优化方法：采用 **梯度下降法** 或 **其变种** 来优化损失函数，通过迭代更新权重和偏置值，使损失函数不断减小。\n",
    "- 迭代更新：在每次迭代中，使用当前的权重和偏置值对训练数据集进行预测，计算预测值与真实标签之间的误差，并根据误差值来调整权重和偏置值。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68992501-aad6-4b68-a24f-e0e69c10c694",
   "metadata": {},
   "source": [
    "<center><img src=\"images/01-deeplearning_perceptron/perceptron-detail-2.png\" style=\"width:80%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a74e06-e8e9-44d5-aeec-ac17db05e857",
   "metadata": {},
   "source": [
    "<center>图 1.6：感知机的反向传播网络更新权重值</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd3d13c-7cf6-427b-b75a-f06ddff28a16",
   "metadata": {},
   "source": [
    "### 感知机训练的数学推导过程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9916a4-e646-44e4-9e91-7fbf62595d24",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2657995-e27e-43c1-95cd-ac9c99c461ef",
   "metadata": {},
   "source": [
    "### 使用 PyTorch 框架训练感知机"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fad18d0-0632-4f2e-bb46-43c85be6ed9d",
   "metadata": {},
   "source": [
    "## **2. 多层感知机（MLP）**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbb8041-eaf9-42d3-9b8e-f43dd3d5cbb7",
   "metadata": {},
   "source": [
    "<style>\n",
    "  table {\n",
    "    width: 100%;\n",
    "    border-collapse: collapse;\n",
    "  }\n",
    "  th, td {\n",
    "    border: 1px solid black;\n",
    "    padding: 8px;\n",
    "    text-align: left;\n",
    "  }\n",
    "  th {\n",
    "    width: 100px;\n",
    "  }\n",
    "  td {\n",
    "    width: 150px;\n",
    "  }\n",
    "</style>\n",
    "\n",
    "| 符号    | 显示    |\n",
    "| -----    | -----    |\n",
    "| \\hat    | $\\hat{A}, \\hat{x}, \\hat{y}, \\hat{a}, \\hat{b}$    |\n",
    "| \\widehat    | $\\widehat{A}, \\widehat{x}, \\widehat{y}, \\widehat{a}, \\widehat{b}$    |\n",
    "| \\tilde    | $\\tilde{A}, \\tilde{x}, \\tilde{y}, \\tilde{a}, \\tilde{b}$    |\n",
    "| \\widetilde    | $\\widetilde{A}, \\widetilde{x}, \\widetilde{y}, \\widetilde{a}, \\widetilde{b}$    |\n",
    "| \\overline    | $\\overline{A}, \\overline{x}, \\overline{y}, \\overline{a}, \\overline{b}$    |\n",
    "| \\underline    | $\\underline{A}, \\underline{x}, \\underline{y}, \\underline{a}, \\underline{b}$    |\n",
    "| \\overbrace    | $\\overbrace{A}, \\overbrace{x}, \\overbrace{y}, \\overbrace{a}, \\overbrace{b}$    |\n",
    "| \\underbrace    | $\\underbrace{A}, \\underbrace{x}, \\underbrace{y}, \\underbrace{a}, \\underbrace{b}$    |\n",
    "| \\overleftarrow    | $\\overleftarrow{A}, \\overleftarrow{x}, \\overleftarrow{y}, \\overleftarrow{a}, \\overleftarrow{b}$    |\n",
    "| \\overrightarrow    | $\\overrightarrow{A}, \\overrightarrow{x}, \\overrightarrow{y}, \\overrightarrow{a}, \\overrightarrow{b}$    |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
